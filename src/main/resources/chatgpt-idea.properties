# Default ChatGPT plugin configuration
# Default parameters for request body, witch used for create a completion for the chat message
# POST https://api.openai.com/v1/chat/completions

# ID of the model to use.
chatgpt.models=gpt-4,gpt-4-0314,gpt-4-32k,gpt-4-32k-0314,gpt-3.5-turbo,gpt-3.5-turbo-0301
# Default selected model
chatgpt.selected_model=gpt-3.5-turbo

# Role for the messages to generate chat completions for
chatgpt.messages.roles=assistant,system,user

# Default selected role
chatgpt.messages.selected_role=user

# What sampling temperature to use, between 0 and 2. Higher values like 0.8 will make the output more random,
# while lower values like 0.2 will make it more focused and deterministic.
chatgpt.temperature=1.0

# An alternative to sampling with temperature, called nucleus sampling,
# where the model considers the results of the tokens with top_p probability mass.
# So 0.1 means only the tokens comprising the top 10% probability mass are considered.
chatgpt.top_p=1

# How many chat completion choices to generate for each input message.
chatgpt.n=1

# If set, partial message deltas will be sent, like in ChatGPT.
# Tokens will be sent as data-only server-sent events as they become available,
# with the stream terminated by a data: [DONE] message.
# See the OpenAI Cookbook for https://github.com/openai/openai-cookbook/blob/main/examples/How_to_stream_completions.ipynb.
chatgpt.stream=false

# Up to 4 sequences where the API will stop generating further tokens.
chatgpt.stop=null

# The maximum number of tokens to generate in the chat completion.
chatgpt.max_tokens=inf

# Number between -2.0 and 2.0. Positive values penalize new tokens based on whether they appear in the text so far,
# increasing the model's likelihood to talk about new topics.
chatgpt.presence_penalty=0

# Number between -2.0 and 2.0. Positive values penalize new tokens based on their existing frequency in the text so far,
# decreasing the model's likelihood to repeat the same line verbatim.
chatgpt.frequency_penalty=0

# Modify the likelihood of specified tokens appearing in the completion.
chatgpt.logit_bias=null

# A unique identifier representing your end-user, which can help OpenAI to monitor and detect abuse.
chatgpt.user=
