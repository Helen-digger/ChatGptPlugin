chatgpt.message.setting.apikey.label=The API Key
chatgpt.message.setting.models.label=The model to use
chatgpt.message.setting.roles.label=Role for the messages
chatgpt.message.setting.optional.label=Optional parameters
chatgpt.message.setting.temperature.label=Temperature (sampling temperature)
chatgpt.message.setting.top_p.label=Top p (Nucleus sampling)
chatgpt.message.setting.n.label=N (Completion choices)
chatgpt.message.setting.stream.label=Stream (Partial message deltas will be sent)
chatgpt.message.setting.stop.label=Stop (4 sequences will stop generating)
chatgpt.message.setting.max_tokens.label=Max tokens
chatgpt.message.setting.presence_penalty.label=Presence penalty
chatgpt.message.setting.frequency_penalty.label=Frequency penalty
chatgpt.message.setting.logit_bias.label=Logit bias
chatgpt.message.setting.user.label=User

chatgpt.message.setting.apikey.tooltip=The API Key
chatgpt.message.setting.models.tooltip=ID of the model to use.
chatgpt.message.setting.roles.tooltip=Role for the messages to generate chat completions for
chatgpt.message.setting.optional.tooltip=Optional parameters
chatgpt.message.setting.temperature.tooltip=Higher values like 0.8 will make the output more random, while lower values like 0.2 will make it more focused and deterministic.
chatgpt.message.setting.top_p.tooltip=the model considers the results of the tokens with top_p probability mass. So 0.1 means only the tokens comprising the top 10% probability mass are considered.
chatgpt.message.setting.n.tooltip=How many chat completion choices to generate for each input message.
chatgpt.message.setting.stream.tooltip=If set, partial message deltas will be sent, like in ChatGPT.
chatgpt.message.setting.stop.tooltip=Up to 4 sequences where the API will stop generating further tokens.
chatgpt.message.setting.max_tokens.tooltip=The maximum number of tokens to generate in the chat completion.
chatgpt.message.setting.presence_penalty.tooltip=Number between -2.0 and 2.0. Positive values penalize new tokens based on whether they appear in the text so far, increasing the model's likelihood to talk about new topics.
chatgpt.message.setting.frequency_penalty.tooltip=Number between -2.0 and 2.0. Positive values penalize new tokens based on their existing frequency in the text so far, decreasing the model's likelihood to repeat the same line verbatim.
chatgpt.message.setting.logit_bias.tooltip=Modify the likelihood of specified tokens appearing in the completion.
chatgpt.message.setting.user.tooltip=A unique identifier representing your end-user, which can help OpenAI to monitor and detect abuse.


error=error